{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5b81e3",
   "metadata": {},
   "source": [
    "# Multiple Regression Example\n",
    "\n",
    "In this example, we apply multiple regression to analyze the relationship between several proteins and a clinical variable, BMI (Body Mass Index). We perform Ridge Regression using regularization to prevent overfitting, and visualize how well the model predicts BMI from the selected protein features.\n",
    "\n",
    "## Data Loading and Preparation\n",
    "\n",
    "The first step involves loading and preparing data from the CPTAC (Clinical Proteomic Tumor Analysis Consortium) database for Lung Squamous Cell Carcinoma (LSCC). We retrieve proteomics data and a relevant clinical variable (BMI), then merge these datasets based on matching patient records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797c4c4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cptac\n",
    "import cptac.utils as ut\n",
    "en = cptac.Lscc()\n",
    "en.list_data_sources()\n",
    "prot = en.get_proteomics(\"umich\")\n",
    "prot = ut.reduce_multiindex(df=prot, tuples=True)\n",
    "clin_var = \"bmi\"\n",
    "clinical = en.get_clinical('mssm')[[clin_var]]\n",
    "clin_and_prot = clinical.join(prot, how='inner').dropna(subset=[clin_var])\n",
    "\n",
    "relevant_prot = [('POLI', 'ENSP00000462664.1'), ('MYL4', 'ENSP00000347055.1'), ('NRP2', 'ENSP00000350432.5'), ('CFHR2', 'ENSP00000356385.4'), ('SMAD2', 'ENSP00000262160.6'), ('KIAA1328', 'ENSP00000280020.5')]\n",
    "variables_df = clin_and_prot.loc[:, [clin_var] + relevant_prot ].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db517ca",
   "metadata": {},
   "source": [
    "* **Clinical Data**: We extract BMI as the clinical variable.\n",
    "* **Proteomics Data**: We use proteomic measurements from several proteins (POLI, MYL4, NRP2, CFHR2, SMAD2, and KIAA1328) as our independent variables.\n",
    "* **Data Joining**: The clinical and proteomics data are merged into a single dataframe and missing values are handled.\n",
    "\n",
    "## Defining the Ridge Regression Model\n",
    "\n",
    "Ridge regression adds a regularization term to penalize large coefficients, helping to control model complexity and reduce overfitting. The following steps define the ridge regression loss function and optimize it using the `scipy.optimize.minimize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "X = variables_df.drop(columns=[clin_var])\n",
    "y = variables_df[clin_var].values\n",
    "\n",
    "# Standardize features\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Set the regularization strength \n",
    "lambda_ridge = 0.5\n",
    "\n",
    "# Define the Ridge loss function\n",
    "def ridge_loss(beta, X, y, lambda_ridge):\n",
    "    # Prediction\n",
    "    y_pred = X @ beta[:-1] + beta[-1]  # Last beta is intercept\n",
    "    # Ridge loss: Sum of Squared Errors + regularization term\n",
    "    error = y - y_pred\n",
    "    loss = np.sum(error ** 2) + lambda_ridge * np.sum(beta[:-1] ** 2)\n",
    "    return loss\n",
    "\n",
    "# Initial guess for beta (coefficients and intercept)\n",
    "initial_beta = np.zeros(X.shape[1] + 1)\n",
    "\n",
    "# Optimize the loss function using scipy's minimize\n",
    "opt_result = minimize(ridge_loss, initial_beta, args=(X, y, lambda_ridge), method='L-BFGS-B')\n",
    "\n",
    "# Extract optimized coefficients\n",
    "optimized_beta = opt_result.x\n",
    "\n",
    "# Separate coefficients and intercept\n",
    "coefficients = optimized_beta[:-1]\n",
    "intercept = optimized_beta[-1]\n",
    "\n",
    "print(f\"Optimized coefficients: {coefficients}\")\n",
    "print(f\"Optimized intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc422bb",
   "metadata": {},
   "source": [
    "* **Ridge Loss Function**: The loss function includes the sum of squared errors (SSE) and a regularization term (ùúÜ) applied to the coefficients.\n",
    "* **Optimization**: We initialize the coefficients and intercept to zero and use minimize to find the optimal values by minimizing the ridge loss function.\n",
    "\n",
    "## Visualization: Predicted vs Actual BMI\n",
    "\n",
    "After fitting the model, we calculate the predicted BMI values and plot them against the actual BMI values to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7051042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicted tumor size using optimized coefficients\n",
    "y_pred = X @ coefficients + intercept\n",
    "#y_pred = X @ coefficients_sklearn + intercept_sklearn\n",
    "# y_pred = X @ [0.,0.,0.,0.,1. ] #+ intercept_sklearn\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "plot_df = pd.DataFrame({'Actual': y, 'Predicted': y_pred})\n",
    "\n",
    "# Plot predicted vs actual using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=plot_df, x='Actual', y='Predicted', color='blue', s=60)\n",
    "sns.lineplot(x=[y.min(), y.max()], y=[y.min(), y.max()], color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Actual BMI')\n",
    "plt.ylabel('Predicted BMI')\n",
    "plt.title('Predicted vs Actual BMI')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21399e0",
   "metadata": {},
   "source": [
    "* **Scatter Plot**: The plot compares the actual BMI values against the predicted values from the model. A red dashed line indicates the ideal scenario where predictions perfectly match the actual values.\n",
    "* **Visual Evaluation**: If the points lie close to the red line, the model‚Äôs predictions are accurate. Deviations from this line represent prediction errors.\n",
    "\n",
    "This example demonstrates how multiple regression can be extended with regularization to improve model generalization, particularly when working with clinical and proteomic datasets."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
